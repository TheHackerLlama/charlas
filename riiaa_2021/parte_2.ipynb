{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "parte_2.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO7VdwT6zkQKn9LQu5X9AW+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheHackerLlama/charlas/blob/main/riiaa_2021/parte_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6PV7GkPGOET"
      },
      "source": [
        "## Procesamiento de datos con datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLUN_pkEMU57"
      },
      "source": [
        "%%capture\n",
        "!pip install transformers datasets\n",
        "!pip install -U huggingface_hub\n",
        "!apt-get install git-lfs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfmVAq1hII5K"
      },
      "source": [
        "!huggingface-cli login"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggGWJRd8HGXT"
      },
      "source": [
        "!git config --global user.email \"osanseviero@gmail.com\"\n",
        "!git config --global user.name \"Omar Sanseviero\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQRlBtGfGybs"
      },
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "from datasets import ClassLabel\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "def show_random_elements(dataset, num_examples=10):\n",
        "    \"Taken from https://github.com/huggingface/notebooks/blob/master/examples/text_classification.ipynb\"\n",
        "    \n",
        "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
        "    picks = []\n",
        "    for _ in range(num_examples):\n",
        "        pick = random.randint(0, len(dataset)-1)\n",
        "        while pick in picks:\n",
        "            pick = random.randint(0, len(dataset)-1)\n",
        "        picks.append(pick)\n",
        "    \n",
        "    df = pd.DataFrame(dataset[picks])\n",
        "    for column, typ in dataset.features.items():\n",
        "        if isinstance(typ, ClassLabel):\n",
        "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
        "    display(HTML(df.to_html()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQaU-rmPMZno"
      },
      "source": [
        "from datasets import list_datasets\n",
        "\n",
        "datasets = list_datasets()\n",
        "print(f\"Hay {len(datasets)} datasets disponibles en el Hub.\")\n",
        "print(f\"Los primeros 10 son: {datasets[:10]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcqPlRdkNnDF"
      },
      "source": [
        "metadata = list_datasets(with_details=True)[datasets.index(\"amazon_reviews_multi\")]\n",
        "\n",
        "print(\"Description:\", metadata.description, \"\\n\")\n",
        "\n",
        "# Show first 8 lines of the citation string\n",
        "print(\"Citation:\", \"\\n\".join(metadata.citation.split(\"\\n\")[:8]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jO1_F1KaMuhx"
      },
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"amazon_reviews_multi\", \"es\")\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G775UUVfG5Hc"
      },
      "source": [
        "show_random_elements(dataset[\"train\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tr-bbAlsNlX3"
      },
      "source": [
        "dataset.set_format(\"pandas\")\n",
        "df = dataset[\"train\"][:]\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSYUE34HPtYt"
      },
      "source": [
        "df[\"product_category\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5txbM3USGEeL"
      },
      "source": [
        "df[\"stars\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qkvbBPUGF2a"
      },
      "source": [
        "dataset.reset_format()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgG4-Dw-GSJ9"
      },
      "source": [
        "## Crear un label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCfZGLNQGRy0"
      },
      "source": [
        "dataset = dataset.filter(lambda x : x[\"stars\"] != 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnRdTURzGdem"
      },
      "source": [
        "def merge_star_ratings(examples):\n",
        "    if examples[\"stars\"] <= 2:\n",
        "        label = 0\n",
        "    else:\n",
        "        label = 1\n",
        "    return {\"labels\": label}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dmf69U8tGfTG"
      },
      "source": [
        "dataset = dataset.map(merge_star_ratings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z23QJJuwGgeW"
      },
      "source": [
        "show_random_elements(dataset[\"train\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6cFqvo3HEmc"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CklQMHhuGjx_"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_checkpoint = \"BSC-TeMU/roberta-base-bne\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RkbmH55HHQy"
      },
      "source": [
        "tokenizer.vocab_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IK5aJORDHIx5"
      },
      "source": [
        "text = \"¡hola, me llamo omar!\"\n",
        "tokenized_text = tokenizer.encode(text)\n",
        "\n",
        "for token in tokenized_text:\n",
        "    print(token, tokenizer.decode([token]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cKc2YBXHK5M"
      },
      "source": [
        "encoded_text = tokenizer(text, return_tensors=\"pt\")\n",
        "encoded_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvD1IoviHPQT"
      },
      "source": [
        "def tokenize_reviews(examples):\n",
        "  return tokenizer(examples[\"review_body\"], truncation=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxJrUNolHTi7"
      },
      "source": [
        "columns = dataset[\"train\"].column_names\n",
        "columns.remove(\"labels\")\n",
        "encoded_dataset = dataset.map(tokenize_reviews, batched=True, remove_columns=columns)\n",
        "encoded_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SX4-YIx0HZlc"
      },
      "source": [
        "encoded_dataset[\"train\"][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSU0vp9LHf77"
      },
      "source": [
        "## Cargar un modelo pre-entrenado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPCvYPuSHdnd"
      },
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "num_labels = 2\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wS2okoY1Hxi6"
      },
      "source": [
        "encoded_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_CPgoCxHi8Y"
      },
      "source": [
        "outputs = model(**encoded_text)\n",
        "outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXJmt0UfH6Gx"
      },
      "source": [
        "## Especificar una métrica"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6TS0w4GHnox"
      },
      "source": [
        "from datasets import load_metric \n",
        "\n",
        "metric = load_metric(\"accuracy\")\n",
        "metric"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNipc0cTH5iA"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6K_mADxXIDTz"
      },
      "source": [
        "## Fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZ7znEpdIBGB"
      },
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "model_name = model_checkpoint.split(\"/\")[-1]\n",
        "\n",
        "batch_size = 16\n",
        "num_train_epochs=1 # Aumentar a 2\n",
        "num_train_samples = 2000 # Aumentar a 20000\n",
        "train_dataset = encoded_dataset[\"train\"].shuffle(seed=42).select(range(num_train_samples))\n",
        "logging_steps = len(train_dataset) // (2 * batch_size * num_train_epochs)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"results\",\n",
        "    num_train_epochs=num_train_epochs,     \n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\", \n",
        "    logging_steps=logging_steps,\n",
        "    push_to_hub=True,\n",
        "    push_to_hub_model_id=f\"{model_name}-finetuned-amazon_reviews_multi\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoUVpugVIhUb"
      },
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model, \n",
        "    args=training_args, \n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=encoded_dataset[\"validation\"],\n",
        "    tokenizer=tokenizer\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPTZiREjInRM"
      },
      "source": [
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_35LF2NJxLv"
      },
      "source": [
        "trainer.push_to_hub()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zASROYu5LF-u"
      },
      "source": [
        "## Utilizando el modelo recién entrenado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQyoYTyuLEeq"
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "model_checkpoint = \"hackertec/roberta-base-bne-finetuned-amazon_reviews_multi\"\n",
        "pipe = pipeline(\"sentiment-analysis\", model=model_checkpoint)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFjYm2_qLKx5"
      },
      "source": [
        "pipe(\"¡me encanta el ipad!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPkNjL8XLK_U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}